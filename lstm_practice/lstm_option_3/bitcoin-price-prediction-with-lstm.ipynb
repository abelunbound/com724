{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bd2b0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:22:29.385315Z",
     "iopub.status.busy": "2021-11-09T08:22:29.384708Z",
     "iopub.status.idle": "2021-11-09T08:22:37.325011Z",
     "shell.execute_reply": "2021-11-09T08:22:37.325524Z",
     "shell.execute_reply.started": "2021-11-09T08:11:07.476205Z"
    },
    "papermill": {
     "duration": 7.986193,
     "end_time": "2021-11-09T08:22:37.325835",
     "exception": false,
     "start_time": "2021-11-09T08:22:29.339642",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n",
    "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from itertools import product\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "## These 3 lines are from the original notebook.\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout\n",
    "# from tensorflow.keras.layers import LSTM\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from itertools import cycle\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550149fd",
   "metadata": {
    "papermill": {
     "duration": 0.035769,
     "end_time": "2021-11-09T08:22:37.397747",
     "exception": false,
     "start_time": "2021-11-09T08:22:37.361978",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Transformation of time series into supervision problems\n",
    "\n",
    "Time series data needs to be prepared before training a supervised learning model (such as LSTM neural network). For example, a unary time series is represented as an observation vector:\n",
    "\n",
    "```\n",
    "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "```\n",
    "\n",
    "The supervised learning algorithm requires data to be provided as a set of samples, where each sample has an input component X and an output component y. The model will learn how to map input to output from the provided examples.\n",
    "\n",
    "\n",
    "The time series must be converted into samples with input and output components .  For a univariate time series problem that is interested in one-step forecasting, you can use the observations at the previous time point as input and the observations at the current time point as the output. For example, the above 10-step univariate sequence can be expressed as a supervised learning problem, the input is 3 time steps, and the output is 1 time step, as shown below:\n",
    "\n",
    "X *******   Y\n",
    "\n",
    "===============\n",
    " \n",
    "[1, 2, 3],  [4]\n",
    "\n",
    "[2, 3, 4],  [5]\n",
    "\n",
    "[3, 4, 5],  [6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300b773c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:22:37.474046Z",
     "iopub.status.busy": "2021-11-09T08:22:37.473162Z",
     "iopub.status.idle": "2021-11-09T08:22:43.282686Z",
     "shell.execute_reply": "2021-11-09T08:22:43.283134Z",
     "shell.execute_reply.started": "2021-11-09T07:52:07.794604Z"
    },
    "papermill": {
     "duration": 5.849088,
     "end_time": "2021-11-09T08:22:43.283293",
     "exception": false,
     "start_time": "2021-11-09T08:22:37.434205",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'btc_ohlc_Oct_2015_to_Oct_2021.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m root_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbtc_ohlc_Oct_2015_to_Oct_2021.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# btc_input_df = pd.read_csv(root_path, nrows=500)\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m btc_input_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# btc_input_df = (btc_input_df.set_index('close')\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m#                 .applymap('{:,.2f}'.format))\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# btc_input_df = btc_input_df.rename_axis('time').reset_index()\u001B[39;00m\n\u001B[0;32m     17\u001B[0m btc_input_df\u001B[38;5;241m.\u001B[39mtail()\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    310\u001B[0m     )\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    666\u001B[0m     dialect,\n\u001B[0;32m    667\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    677\u001B[0m )\n\u001B[0;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    931\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 934\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1214\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1215\u001B[0m \u001B[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n\u001B[0;32m   1216\u001B[0m \u001B[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n\u001B[0;32m   1217\u001B[0m \u001B[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n\u001B[1;32m-> 1218\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-overload]\u001B[39;49;00m\n\u001B[0;32m   1219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1226\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1227\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1228\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1229\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\pandas\\io\\common.py:786\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    783\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    785\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 786\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    787\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    788\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    789\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    793\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    794\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    795\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'btc_ohlc_Oct_2015_to_Oct_2021.csv'"
     ]
    }
   ],
   "source": [
    "# Google Drive Root Path\n",
    "# root_path = '/content/drive/MyDrive/Datasets_For_Working/Bitcoin_2015-2021-30-Oct-2021/3_pull.csv'\n",
    "\n",
    "# Local Machine Root Path\n",
    "# root_path = './input/btc_ohlc_Oct_2015_to_Oct_2021.csv'\n",
    "\n",
    "# Kaggle Root Path\n",
    "root_path = 'btc_ohlc_Oct_2015_to_Oct_2021.csv'\n",
    "\n",
    "\n",
    "# btc_input_df = pd.read_csv(root_path, nrows=500)\n",
    "btc_input_df = pd.read_csv(root_path)\n",
    "# btc_input_df = (btc_input_df.set_index('close')\n",
    "#                 .applymap('{:,.2f}'.format))\n",
    "# btc_input_df = btc_input_df.rename_axis('time').reset_index()\n",
    "\n",
    "btc_input_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda0fee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:22:43.362263Z",
     "iopub.status.busy": "2021-11-09T08:22:43.361494Z",
     "iopub.status.idle": "2021-11-09T08:22:43.365135Z",
     "shell.execute_reply": "2021-11-09T08:22:43.364507Z",
     "shell.execute_reply.started": "2021-11-09T07:52:13.797881Z"
    },
    "papermill": {
     "duration": 0.04578,
     "end_time": "2021-11-09T08:22:43.365263",
     "exception": false,
     "start_time": "2021-11-09T08:22:43.319483",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "btc_input_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4a59f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "btc_no_time_df = btc_input_df.drop(columns=['time'])\n",
    "btc_no_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8303d1bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:22:43.498535Z",
     "iopub.status.busy": "2021-11-09T08:22:43.497364Z",
     "iopub.status.idle": "2021-11-09T08:22:43.958668Z",
     "shell.execute_reply": "2021-11-09T08:22:43.958124Z",
     "shell.execute_reply.started": "2021-11-09T07:52:13.806232Z"
    },
    "papermill": {
     "duration": 0.557005,
     "end_time": "2021-11-09T08:22:43.958818",
     "exception": false,
     "start_time": "2021-11-09T08:22:43.401813",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "btc_input_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c03cff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:22:44.045891Z",
     "iopub.status.busy": "2021-11-09T08:22:44.045249Z",
     "iopub.status.idle": "2021-11-09T08:22:44.047768Z",
     "shell.execute_reply": "2021-11-09T08:22:44.048399Z",
     "shell.execute_reply.started": "2021-11-09T07:52:14.369319Z"
    },
    "papermill": {
     "duration": 0.051665,
     "end_time": "2021-11-09T08:22:44.048558",
     "exception": false,
     "start_time": "2021-11-09T08:22:43.996893",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "btc_input_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d0aafa",
   "metadata": {
    "papermill": {
     "duration": 0.038031,
     "end_time": "2021-11-09T08:22:44.124503",
     "exception": false,
     "start_time": "2021-11-09T08:22:44.086472",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Convert 'time' column from object dtype to datetime dtype\n",
    "\n",
    "From above I can see that the 'time' column is being treated as an object rather than as dates. To fix this, I will use the (pd.to_datetime() function which converts the arguments to dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a49cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:22:45.211367Z",
     "iopub.status.busy": "2021-11-09T08:22:45.209919Z",
     "iopub.status.idle": "2021-11-09T08:22:45.259856Z",
     "shell.execute_reply": "2021-11-09T08:22:45.260322Z",
     "shell.execute_reply.started": "2021-11-09T07:52:14.385146Z"
    },
    "papermill": {
     "duration": 1.099083,
     "end_time": "2021-11-09T08:22:45.260495",
     "exception": false,
     "start_time": "2021-11-09T08:22:44.161412",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "btc_input_df_datetype = btc_input_df.astype({'time': 'datetime64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33361baf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:22:45.339999Z",
     "iopub.status.busy": "2021-11-09T08:22:45.339448Z",
     "iopub.status.idle": "2021-11-09T08:22:45.348118Z",
     "shell.execute_reply": "2021-11-09T08:22:45.348933Z",
     "shell.execute_reply.started": "2021-11-09T07:52:15.485196Z"
    },
    "papermill": {
     "duration": 0.050616,
     "end_time": "2021-11-09T08:22:45.349139",
     "exception": false,
     "start_time": "2021-11-09T08:22:45.298523",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "btc_input_df_datetype.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b7eb8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:22:45.481389Z",
     "iopub.status.busy": "2021-11-09T08:22:45.480796Z",
     "iopub.status.idle": "2021-11-09T08:22:45.587635Z",
     "shell.execute_reply": "2021-11-09T08:22:45.586987Z",
     "shell.execute_reply.started": "2021-11-09T07:52:15.499397Z"
    },
    "papermill": {
     "duration": 0.147312,
     "end_time": "2021-11-09T08:22:45.587809",
     "exception": false,
     "start_time": "2021-11-09T08:22:45.440497",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Null Values:',btc_input_df_datetype.isnull().values.sum())\n",
    "print('If any NA values:', btc_input_df_datetype.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a0421f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:22:45.677061Z",
     "iopub.status.busy": "2021-11-09T08:22:45.676410Z",
     "iopub.status.idle": "2021-11-09T08:22:45.678882Z",
     "shell.execute_reply": "2021-11-09T08:22:45.679368Z",
     "shell.execute_reply.started": "2021-11-09T07:52:15.615682Z"
    },
    "papermill": {
     "duration": 0.053201,
     "end_time": "2021-11-09T08:22:45.679512",
     "exception": false,
     "start_time": "2021-11-09T08:22:45.626311",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "btc_input_df_datetype.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd374188",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:22:45.761484Z",
     "iopub.status.busy": "2021-11-09T08:22:45.760894Z",
     "iopub.status.idle": "2021-11-09T08:22:45.772886Z",
     "shell.execute_reply": "2021-11-09T08:22:45.773402Z",
     "shell.execute_reply.started": "2021-11-09T07:52:15.636141Z"
    },
    "papermill": {
     "duration": 0.054771,
     "end_time": "2021-11-09T08:22:45.773558",
     "exception": false,
     "start_time": "2021-11-09T08:22:45.718787",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "btc_input_df_datetype.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369485c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:22:45.855884Z",
     "iopub.status.busy": "2021-11-09T08:22:45.855251Z",
     "iopub.status.idle": "2021-11-09T08:23:07.129023Z",
     "shell.execute_reply": "2021-11-09T08:23:07.129522Z",
     "shell.execute_reply.started": "2021-11-09T07:52:15.654405Z"
    },
    "papermill": {
     "duration": 21.316539,
     "end_time": "2021-11-09T08:23:07.129743",
     "exception": false,
     "start_time": "2021-11-09T08:22:45.813204",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "btc_input_df_datetype.set_index(\"time\").close.plot(figsize=(24,7), title=\"Bitcoin Weighted Price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6dc06d",
   "metadata": {
    "papermill": {
     "duration": 0.042862,
     "end_time": "2021-11-09T08:23:07.217361",
     "exception": false,
     "start_time": "2021-11-09T08:23:07.174499",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Lag Plot\n",
    "\n",
    "Lag plot are used to observe the autocorrelation. These are crucial when we try to correct the trend and stationarity and we have to use smoothing functions. Lag plot helps us to understand the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58326d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:23:07.309860Z",
     "iopub.status.busy": "2021-11-09T08:23:07.309102Z",
     "iopub.status.idle": "2021-11-09T08:23:56.368247Z",
     "shell.execute_reply": "2021-11-09T08:23:56.368812Z",
     "shell.execute_reply.started": "2021-11-09T07:52:36.192939Z"
    },
    "papermill": {
     "duration": 49.110194,
     "end_time": "2021-11-09T08:23:56.368974",
     "exception": false,
     "start_time": "2021-11-09T08:23:07.258780",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "plt.suptitle('Lag Plots', fontsize=22)\n",
    "\n",
    "plt.subplot(3,3,1)\n",
    "pd.plotting.lag_plot(btc_input_df_datetype['close'], lag=1) #minute lag\n",
    "plt.title('1-Minute Lag')\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "pd.plotting.lag_plot(btc_input_df_datetype['close'], lag=60) #hourley lag\n",
    "plt.title('1-Hour Lag')\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "pd.plotting.lag_plot(btc_input_df_datetype['close'], lag=1440) #Daily lag\n",
    "plt.title('Daily Lag')\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "pd.plotting.lag_plot(btc_input_df_datetype['close'], lag=10080) #weekly lag\n",
    "plt.title('Weekly Lag')\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "pd.plotting.lag_plot(btc_input_df_datetype['close'], lag=43200) #month lag\n",
    "plt.title('1-Month Lag')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b476f2bc",
   "metadata": {
    "papermill": {
     "duration": 0.044329,
     "end_time": "2021-11-09T08:23:56.457901",
     "exception": false,
     "start_time": "2021-11-09T08:23:56.413572",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "We can see that there is a positive correlation for minute, hour and daily lag plots. \n",
    "\n",
    "Correlation decreases drastically with Weekly Lag and absolutely no correlation for month lag plots.\n",
    "\n",
    "It makes sense to re-sample our data atmost at the Daily level, thereby preserving the autocorrelation as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd599a6",
   "metadata": {
    "papermill": {
     "duration": 0.043682,
     "end_time": "2021-11-09T08:23:56.546940",
     "exception": false,
     "start_time": "2021-11-09T08:23:56.503258",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Making data ready for LSTM - pd.to_datetime(unit='s) and then groupby('date')\n",
    "\n",
    "## pd.to_datetime unit='s'\n",
    "\n",
    "The unit of the arg (D,s,ms,us,ns) denote the unit, which is an integer or float number. This will be based off the origin. Example, with unit=’ms’ and origin=’unix’ (the default), this would calculate the number of milliseconds to the unix epoch start.\n",
    "\n",
    "Say you pass an int as your arg (like 20203939), with unit, you’ll be able specify what unit your int is away from the origin. In the example here, if we set unit=’s’, this means pandas will interpret 20203939 as 20,203,939 seconds away from the origin. Available units are [D,s,ms,us,ns]. \n",
    "[Source](https://www.dataindependent.com/pandas/pandas-to-datetime/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c9064d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:23:56.639356Z",
     "iopub.status.busy": "2021-11-09T08:23:56.638765Z",
     "iopub.status.idle": "2021-11-09T08:23:58.943697Z",
     "shell.execute_reply": "2021-11-09T08:23:58.942755Z",
     "shell.execute_reply.started": "2021-11-09T07:53:25.811071Z"
    },
    "papermill": {
     "duration": 2.351959,
     "end_time": "2021-11-09T08:23:58.943895",
     "exception": false,
     "start_time": "2021-11-09T08:23:56.591936",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "btc_input_df_datetype['date'] = pd.to_datetime(btc_input_df_datetype['time'],unit='s').dt.date\n",
    "\n",
    "# display(btc_input_df_datetype.tail())\n",
    "\n",
    "group = btc_input_df_datetype.groupby('date')\n",
    "btc_closing_price_groupby_date = group['close'].mean()\n",
    "btc_closing_price_groupby_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa1db53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:23:59.040525Z",
     "iopub.status.busy": "2021-11-09T08:23:59.039593Z",
     "iopub.status.idle": "2021-11-09T08:23:59.048614Z",
     "shell.execute_reply": "2021-11-09T08:23:59.049444Z",
     "shell.execute_reply.started": "2021-11-09T07:53:28.172949Z"
    },
    "papermill": {
     "duration": 0.058979,
     "end_time": "2021-11-09T08:23:59.049687",
     "exception": false,
     "start_time": "2021-11-09T08:23:58.990708",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(btc_closing_price_groupby_date.head(10))\n",
    "\n",
    "print(\"Length of btc_closing_price_groupby_date :\", len(btc_closing_price_groupby_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4517fb",
   "metadata": {
    "papermill": {
     "duration": 0.047744,
     "end_time": "2021-11-09T08:23:59.148324",
     "exception": false,
     "start_time": "2021-11-09T08:23:59.100580",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399592d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:23:59.244079Z",
     "iopub.status.busy": "2021-11-09T08:23:59.243159Z",
     "iopub.status.idle": "2021-11-09T08:23:59.248558Z",
     "shell.execute_reply": "2021-11-09T08:23:59.249109Z",
     "shell.execute_reply.started": "2021-11-09T07:53:28.184883Z"
    },
    "papermill": {
     "duration": 0.054267,
     "end_time": "2021-11-09T08:23:59.249263",
     "exception": false,
     "start_time": "2021-11-09T08:23:59.194996",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_days = 60\n",
    "\n",
    "# Set Train data to be uplo ( Total data length - prediction_days )\n",
    "df_train= btc_closing_price_groupby_date[:len(btc_closing_price_groupby_date)-prediction_days].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "# Set Test data to be the last prediction_days (or 60 days in this case)\n",
    "df_test= btc_closing_price_groupby_date[len(btc_closing_price_groupby_date)-prediction_days:].values.reshape(-1,1)\n",
    "# df_train\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85184d95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:23:59.343379Z",
     "iopub.status.busy": "2021-11-09T08:23:59.342454Z",
     "iopub.status.idle": "2021-11-09T08:23:59.347337Z",
     "shell.execute_reply": "2021-11-09T08:23:59.347903Z",
     "shell.execute_reply.started": "2021-11-09T07:53:28.196806Z"
    },
    "papermill": {
     "duration": 0.053552,
     "end_time": "2021-11-09T08:23:59.348062",
     "exception": false,
     "start_time": "2021-11-09T08:23:59.294510",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e9c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:23:59.443045Z",
     "iopub.status.busy": "2021-11-09T08:23:59.442151Z",
     "iopub.status.idle": "2021-11-09T08:23:59.712867Z",
     "shell.execute_reply": "2021-11-09T08:23:59.713366Z",
     "shell.execute_reply.started": "2021-11-09T07:53:28.211137Z"
    },
    "papermill": {
     "duration": 0.319696,
     "end_time": "2021-11-09T08:23:59.713546",
     "exception": false,
     "start_time": "2021-11-09T08:23:59.393850",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chosen_col = 'Close'\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(13, 7))\n",
    "\n",
    "ax.plot(df_train, label='Train', linewidth=2)\n",
    "ax.plot(df_test, label='Test', linewidth=2)\n",
    "ax.set_ylabel('Price USD', fontsize=14)\n",
    "ax.set_title('BitCoin Closeprice Train-Test Data', fontsize=16)\n",
    "ax.legend(loc='best', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e9589",
   "metadata": {
    "papermill": {
     "duration": 0.048747,
     "end_time": "2021-11-09T08:23:59.812142",
     "exception": false,
     "start_time": "2021-11-09T08:23:59.763395",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Mix Max Scaling of Data post Train-Test Split\n",
    "\n",
    "Scaling must be done after the data has been split into training and test sets — with each being scaled separately. \n",
    "\n",
    "A common mistake when first using the LSTM is to first normalize the data before splitting the data.\n",
    "\n",
    "The reason this is erroneous is that the normalization technique will use data from the test sets as a reference point when scaling the data as a whole. This will inadvertently influence the values of the training data, essentially resulting in data leakage from the test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99304eda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:23:59.913917Z",
     "iopub.status.busy": "2021-11-09T08:23:59.912834Z",
     "iopub.status.idle": "2021-11-09T08:23:59.918170Z",
     "shell.execute_reply": "2021-11-09T08:23:59.918743Z",
     "shell.execute_reply.started": "2021-11-09T07:53:28.453531Z"
    },
    "papermill": {
     "duration": 0.057689,
     "end_time": "2021-11-09T08:23:59.918930",
     "exception": false,
     "start_time": "2021-11-09T08:23:59.861241",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler_train = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train = scaler_train.fit_transform(df_train)\n",
    "\n",
    "scaler_test = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_test = scaler_test.fit_transform(df_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1228189d",
   "metadata": {
    "papermill": {
     "duration": 0.049184,
     "end_time": "2021-11-09T08:24:00.018084",
     "exception": false,
     "start_time": "2021-11-09T08:23:59.968900",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Dataset Generator for LSTM\n",
    "\n",
    "We will frame the problem to take a window of the last so many number of days of data to predict the current days data.\n",
    "\n",
    "To achieve this, we will define a new function named `dataset_generator_lstm()` that will split the input sequence into windows of data appropriate for fitting a supervised learning model, like an LSTM\n",
    "\n",
    "\n",
    "For example, if the sequence was:\n",
    "\n",
    "1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
    "\n",
    "\n",
    "Then the samples for training the model will look like:\n",
    "\n",
    "```\n",
    "\n",
    "Input \t\t\t\t| Output\n",
    "1, 2, 3, 4, 5 \t\t6\n",
    "2, 3, 4, 5, 6 \t\t7\n",
    "3, 4, 5, 6, 7 \t\t8\n",
    "\n",
    "```\n",
    "\n",
    "LSTMs expect each sample in the dataset to have two dimensions; the first is the number of time steps (in the above case it is 5), and the second is the number of observations per time step (in this case it is 1).\n",
    "\n",
    "Because it is a regression type problem, we will use a linear activation function in the output layer and optimize the mean squared error loss function. We will also evaluate the model using the mean squared error (MAE) metric.\n",
    "\n",
    "## Define look_back period\n",
    "\n",
    "A “lookback period” defines how many previous timesteps are used in order to predict the subsequent timestep. \n",
    "\n",
    "For example if I set the lookback period is to 5, that that means that I am using the time steps at t-4, t-3, t-2, t-1, and t to predict the value at time t+1.\n",
    "\n",
    "For my case below, I will be using a one-step prediction model.\n",
    "\n",
    "### Lookback period\n",
    "\n",
    "\n",
    "```py\n",
    "\n",
    "lookback = 5\n",
    "\n",
    "X_train, Y_train = dataset_generator_lstm(train, lookback)\n",
    "\n",
    "X_val, Y_val = dataset_generator_lstm(val, lookback)\n",
    "\n",
    "```\n",
    "\n",
    "### Quick note on Python slice notation for slicing an array\n",
    "\n",
    "- [1:5] is equivalent to \"from 1 to 5\" (5 not included)\n",
    "\n",
    "- [1:] is equivalent to \"1 to end\"\n",
    "\n",
    "- [len(a):] is equivalent to \"from length of a to end\"\n",
    "\n",
    "In the below function I will generate the train_X array and train_y array for feeding into the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1e5fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:00.120271Z",
     "iopub.status.busy": "2021-11-09T08:24:00.119252Z",
     "iopub.status.idle": "2021-11-09T08:24:00.134344Z",
     "shell.execute_reply": "2021-11-09T08:24:00.133732Z",
     "shell.execute_reply.started": "2021-11-09T07:53:28.462429Z"
    },
    "papermill": {
     "duration": 0.066879,
     "end_time": "2021-11-09T08:24:00.134486",
     "exception": false,
     "start_time": "2021-11-09T08:24:00.067607",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataset_generator_lstm(dataset, look_back=5):\n",
    "    # A “lookback period” defines the window-size of how many\n",
    "    # previous timesteps are used in order to predict\n",
    "    # the subsequent timestep. \n",
    "    dataX, dataY = [], []\n",
    "    \n",
    "    for i in range(len(dataset) - look_back):\n",
    "        window_size_x = dataset[i:(i + look_back), 0]\n",
    "        dataX.append(window_size_x)\n",
    "        dataY.append(dataset[i + look_back, 0]) # this is the label or actual y-value\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "trainX, trainY = dataset_generator_lstm(scaled_train)\n",
    "\n",
    "testX, testY = dataset_generator_lstm(scaled_test)\n",
    "\n",
    "print(\"trainX: \", trainX.shape)\n",
    "print(\"trainY: \", trainY.shape)\n",
    "print(\"testY: \", testX.shape)\n",
    "print(\"testY\", testY.shape)\n",
    "## TTTTTTTTTTTTTTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92187fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:00.237582Z",
     "iopub.status.busy": "2021-11-09T08:24:00.236915Z",
     "iopub.status.idle": "2021-11-09T08:24:00.242209Z",
     "shell.execute_reply": "2021-11-09T08:24:00.242738Z",
     "shell.execute_reply.started": "2021-11-09T07:53:28.483275Z"
    },
    "papermill": {
     "duration": 0.058976,
     "end_time": "2021-11-09T08:24:00.242908",
     "exception": false,
     "start_time": "2021-11-09T08:24:00.183932",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"trainX: \", trainX)\n",
    "# print(\"trainY: \", trainY)\n",
    "# print(\"testY: \", testX)\n",
    "# print(\"testY\", testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd3640",
   "metadata": {
    "papermill": {
     "duration": 0.048996,
     "end_time": "2021-11-09T08:24:00.341345",
     "exception": false,
     "start_time": "2021-11-09T08:24:00.292349",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# For LSTM I need to reshape input to be a 3D Tensor of [samples, time steps, features]\n",
    "\n",
    "    X = numpy.reshape(dataX, (len(dataX), seq_length, 1))\n",
    "\n",
    "**Samples** - This is the len(dataX), or the amount of data points you have.\n",
    "\n",
    "**Time steps** - A sample contains multiple time steps, that is, the width of the sliding window (according to the above example, the time step is 3). Note here that it is distinguished from the sliding step of the sliding window. This is equivalent to the amount of time steps you run your recurrent neural network. If you want your network to have memory of 60 characters, this number should be 60. For this notebook, I am using the window-size to be 5.\n",
    "\n",
    "**Features** - this is the amount of features in every time step. If you are processing pictures, this is the amount of pixels. In this case I have 1 feature (the price of Bitcoin) per time step.\n",
    "\n",
    " ### According to the documentation and the source code, the Keras LSTM input data must be in the form: [batch_size, timesteps, input_dim].\n",
    "\n",
    " In Keras, the number of time steps is equal to the number of LSTM cells. This is what the word “time steps” means in the 3D tensor of the shape [batch_size, timesteps, input_dim].\n",
    "\n",
    "\n",
    "### So to emphasize again, the input to every LSTM layer must be three-dimensional.\n",
    "\n",
    "The three dimensions of this input are:\n",
    "\n",
    "Samples. One sequence is one sample. A batch is comprised of one or more samples.\n",
    "\n",
    "Time Steps. One time step is one point of observation in the sample.\n",
    "\n",
    "Features. One feature is one observation at a time step.\n",
    "\n",
    "This means that the input layer expects a 3D array of data when fitting the model and when making predictions, even if specific dimensions of the array contain a single value, e.g. one sample or one feature.\n",
    "\n",
    "When defining the input layer of your LSTM network, the network assumes you have 1 or more samples and requires that you specify the number of time steps and the number of features. You can do this by specifying a tuple to the “input_shape” argument.\n",
    "\n",
    "-----------------------\n",
    "\n",
    "### Example of LSTM With Single Input Sample where you have one sequence of multiple time steps and one feature.\n",
    "\n",
    "For example, this could be a sequence of 10 values:\n",
    "\n",
    "```\n",
    "0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\n",
    "\n",
    "```\n",
    "\n",
    "1. We can define this sequence of numbers as a NumPy array.\n",
    "\n",
    "2. We can then use the reshape() function on the NumPy array to reshape this one-dimensional array into a three-dimensional array with 1 sample, 10 time steps, and 1 feature at each time step.\n",
    "\n",
    "The reshape() function when called on an array takes one argument which is a tuple defining the new shape of the array. We cannot pass in any tuple of numbers; the reshape must evenly reorganize the data in the array.\n",
    "\n",
    "3. Once reshaped, we can print the new shape of the array.\n",
    "\n",
    "Putting all of this together, the complete example is listed below.\n",
    "\n",
    "```py\n",
    "from numpy import array\n",
    "data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "data = data.reshape((1, 10, 1))\n",
    "print(data.shape)\n",
    "\n",
    "```\n",
    "Running the example prints the new 3D shape of the single sample.\n",
    "\n",
    "```\n",
    "(1, 10, 1)\n",
    "\n",
    "```\n",
    "This data is now ready to be used as input (X) to the LSTM with an input_shape of (10, 1).\n",
    "\n",
    "```py\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(10, 1)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "```\n",
    "\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05aed8d",
   "metadata": {
    "papermill": {
     "duration": 0.049132,
     "end_time": "2021-11-09T08:24:00.439690",
     "exception": false,
     "start_time": "2021-11-09T08:24:00.390558",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "-------------------------------\n",
    "\n",
    "# For LSTM Reshape input ( trainX and testX ) to be 3-D of [samples, time steps, features]\n",
    "\n",
    "### First check the current shape of trainX and testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a61190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:00.541707Z",
     "iopub.status.busy": "2021-11-09T08:24:00.541081Z",
     "iopub.status.idle": "2021-11-09T08:24:00.545542Z",
     "shell.execute_reply": "2021-11-09T08:24:00.546039Z",
     "shell.execute_reply.started": "2021-11-09T07:53:28.494836Z"
    },
    "papermill": {
     "duration": 0.056702,
     "end_time": "2021-11-09T08:24:00.546194",
     "exception": false,
     "start_time": "2021-11-09T08:24:00.489492",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be581c5",
   "metadata": {
    "papermill": {
     "duration": 0.04855,
     "end_time": "2021-11-09T08:24:00.643986",
     "exception": false,
     "start_time": "2021-11-09T08:24:00.595436",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### And now reshape trainX and testX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a73677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:00.744891Z",
     "iopub.status.busy": "2021-11-09T08:24:00.744247Z",
     "iopub.status.idle": "2021-11-09T08:24:00.750621Z",
     "shell.execute_reply": "2021-11-09T08:24:00.751297Z",
     "shell.execute_reply.started": "2021-11-09T07:53:28.505643Z"
    },
    "papermill": {
     "duration": 0.05867,
     "end_time": "2021-11-09T08:24:00.751471",
     "exception": false,
     "start_time": "2021-11-09T08:24:00.692801",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1 ))\n",
    "\n",
    "print(\"Shape of trainX: \", trainX.shape)\n",
    "print(\"Shape of testX: \", testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3dfc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:00.853506Z",
     "iopub.status.busy": "2021-11-09T08:24:00.852924Z",
     "iopub.status.idle": "2021-11-09T08:24:00.864174Z",
     "shell.execute_reply": "2021-11-09T08:24:00.864764Z",
     "shell.execute_reply.started": "2021-11-09T07:53:28.518606Z"
    },
    "papermill": {
     "duration": 0.063616,
     "end_time": "2021-11-09T08:24:00.864939",
     "exception": false,
     "start_time": "2021-11-09T08:24:00.801323",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"trainX: \", trainX)\n",
    "print(\" ********** \")\n",
    "print(\"testX: \", testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da377d2",
   "metadata": {
    "papermill": {
     "duration": 0.050372,
     "end_time": "2021-11-09T08:24:00.966593",
     "exception": false,
     "start_time": "2021-11-09T08:24:00.916221",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Let’s take a look at the normalized window for trainX.\n",
    "\n",
    "```\n",
    "[[[0.00000000e+00]\n",
    "  [1.44159882e-04]\n",
    "  [2.79473948e-04]\n",
    "  [5.34851927e-04]\n",
    "  [4.90695552e-04]]\n",
    "\n",
    " [[1.44159882e-04]\n",
    "  [2.79473948e-04]\n",
    "  [5.34851927e-04]\n",
    "  [4.90695552e-04]\n",
    "  [4.21819458e-04]]\n",
    "\n",
    " [[2.79473948e-04]\n",
    "  [5.34851927e-04]\n",
    "  [4.90695552e-04]\n",
    "  [4.21819458e-04]\n",
    "  [7.33745838e-04]]... ]\n",
    "\n",
    "```\n",
    "Above are the first three entries. We can see that the five time steps immediately prior to the one we are trying to predict move in a stepwise motion.\n",
    "\n",
    "Consider the last value of the first window which is => 4.90695552e-04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2a97b",
   "metadata": {
    "papermill": {
     "duration": 0.049556,
     "end_time": "2021-11-09T08:24:01.066574",
     "exception": false,
     "start_time": "2021-11-09T08:24:01.017018",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# LSTM (Long Short-Term Memory) Mechanism\n",
    "\n",
    "The Long Short-Term Memory, or LSTM, is a recurrent neural network that is comprised of internal gates.\n",
    "\n",
    "Unlike other recurrent neural networks, the network’s internal gates allow the model to be trained successfully using backpropagation through time, or BPTT, and avoid the vanishing gradients problem.\n",
    "\n",
    "In the Keras deep learning library, LSTM layers can be created using the LSTM() class.\n",
    "\n",
    "Creating a layer of LSTM memory units allows you to specify the number of memory units within the layer.\n",
    "\n",
    "Each unit or cell within the layer has an internal cell state, often abbreviated as “c“, and outputs a hidden state, often abbreviated as “h“.\n",
    "\n",
    "The Keras API allows you to access these data, which can be useful or even required when developing sophisticated recurrent neural network architectures, such as the encoder-decoder model.\n",
    "\n",
    "\n",
    "## `input_shape` of LSTM Model - `input_shape` is supposed to be (timesteps, n_features).\n",
    "\n",
    "    input_shape = (95000,360)\n",
    "\n",
    "Keras LSTM takes and input with shape of (n_examples, n_times, n_features) and your layers input has to have this shape\n",
    "\n",
    "To give you an example: if I'm observing the amount of rain and the temperature each hour for 24h in order to predict the weather (1 = good, 0 = bad), and I do that for 365 days, I will have 365 samples, each of which will have 24 timesteps, and 2 variables (one for rain, one for temperature), so my input is going to have the shape (365, 24, 2), and input_shape = (24, 2)\n",
    "\n",
    "\n",
    "## `return_sequences=True`\n",
    "\n",
    "The original LSTM model is comprised of a single hidden LSTM layer followed by a standard feedforward output layer.\n",
    "\n",
    "The Stacked LSTM is an extension to this model that has multiple hidden LSTM layers where each layer contains multiple memory cells.\n",
    "\n",
    "You must set return_sequences=True when stacking LSTM layers so that the second LSTM layer has a compatible n-dimensional sequence input. \n",
    "\n",
    "#### To stack LSTM layers, we need to change the configuration of the prior LSTM layer to output a compatible n-dim array as input for the subsequent layer.\n",
    "\n",
    "We can do this by setting the return_sequences argument on the layer to True (defaults to False). This will return one output for each input time step and provide the compatible n-dim array.\n",
    "\n",
    "## Why Increase Depth of an LSTM ?\n",
    "\n",
    "Stacking LSTM hidden layers makes the model deeper, more accurately earning the description as a deep learning technique.\n",
    "\n",
    "It is the depth of neural networks that is generally attributed to the success of the approach on a wide range of challenging prediction problems.\n",
    "\n",
    "Additional hidden layers can be added to a Multilayer Perceptron neural network to make it deeper. The additional hidden layers are understood to recombine the learned representation from prior layers and create new representations at high levels of abstraction. For example, from lines to shapes to objects.\n",
    "\n",
    "A sufficiently large single hidden layer Multilayer Perceptron can be used to approximate most functions. Increasing the depth of the network provides an alternate solution that requires fewer neurons and trains faster. Ultimately, adding depth it is a type of representational optimization.\n",
    "\n",
    "Given that LSTMs operate on sequence data, it means that the addition of layers adds levels of abstraction of input observations over time. In effect, chunking observations over time or representing the problem at different time scales.\n",
    "\n",
    "Stacked LSTMs are now a stable technique for challenging sequence prediction problems. \n",
    "\n",
    "# Final LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4438cf67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:01.176093Z",
     "iopub.status.busy": "2021-11-09T08:24:01.175247Z",
     "iopub.status.idle": "2021-11-09T08:24:01.178428Z",
     "shell.execute_reply": "2021-11-09T08:24:01.178951Z",
     "shell.execute_reply.started": "2021-11-09T07:53:28.540294Z"
    },
    "papermill": {
     "duration": 0.060031,
     "end_time": "2021-11-09T08:24:01.179115",
     "exception": false,
     "start_time": "2021-11-09T08:24:01.119084",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First checking the values for input_shape = (trainX.shape[1], trainX.shape[2])\n",
    "# Note - `input_shape` of LSTM Model - `input_shape` is supposed to be (timesteps, n_features).\n",
    "\n",
    "print(\"trainX.shape[1] - i.e. timesteps in input_shape = (timesteps, n_features) \", trainX.shape[1])\n",
    "print(\"trainX.shape[2] - i.e. n_features in input_shape = (timesteps, n_features) \", trainX.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c247041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:01.286885Z",
     "iopub.status.busy": "2021-11-09T08:24:01.285918Z",
     "iopub.status.idle": "2021-11-09T08:24:01.746820Z",
     "shell.execute_reply": "2021-11-09T08:24:01.747339Z",
     "shell.execute_reply.started": "2021-11-09T07:53:28.553350Z"
    },
    "papermill": {
     "duration": 0.51592,
     "end_time": "2021-11-09T08:24:01.747513",
     "exception": false,
     "start_time": "2021-11-09T08:24:01.231593",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "# You must set return_sequences=True when stacking LSTM layers so that the second LSTM layer\n",
    "# has a compatible n-dimensional sequence input.\n",
    "# This hyper parameter should be set to False (which is the default value) for the last layer\n",
    "# and true for the other previous layers.\n",
    "\n",
    "regressor.add(LSTM(units = 128, activation = 'relu',return_sequences=True, input_shape = (trainX.shape[1], trainX.shape[2])))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 64, input_shape = (trainX.shape[1], trainX.shape[2])))\n",
    "# regressor.add(LSTM(units = 64, return_sequences = True, input_shape = (trainX.shape[1], trainX.shape[2])))\n",
    "regressor.add(Dropout(0.2))\n",
    "# Note - If I plan to add 3-rd or 4-th layers of LSTM then \n",
    "# I must set return_sequences=True in the 2-nd layer above\n",
    "# so that the 3-rd LSTM layer has a compatible n-dimensional sequence input.\n",
    "\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "# regressor.add(LSTM(units = 64, return_sequences = True, input_shape = (trainX.shape[1], trainX.shape[2])))\n",
    "# regressor.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "# regressor.add(LSTM(units = 64, input_shape = (trainX.shape[1], trainX.shape[2])))\n",
    "# regressor.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "regressor.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a2ede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:01.859939Z",
     "iopub.status.busy": "2021-11-09T08:24:01.859233Z",
     "iopub.status.idle": "2021-11-09T08:24:34.491023Z",
     "shell.execute_reply": "2021-11-09T08:24:34.491550Z",
     "shell.execute_reply.started": "2021-11-09T07:53:29.074954Z"
    },
    "papermill": {
     "duration": 32.69245,
     "end_time": "2021-11-09T08:24:34.491782",
     "exception": false,
     "start_time": "2021-11-09T08:24:01.799332",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from  keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Compiling the LSTM\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "checkpoint_path = 'my_best_model.hdf5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "callbacks = [checkpoint, earlystopping]\n",
    "\n",
    "\n",
    "history = regressor.fit(trainX, trainY, batch_size = 32, epochs = 300, verbose=1, shuffle=False, validation_data=(testX, testY), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f20e1d",
   "metadata": {
    "papermill": {
     "duration": 0.21913,
     "end_time": "2021-11-09T08:24:34.927854",
     "exception": false,
     "start_time": "2021-11-09T08:24:34.708724",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Plot line graph to show Loss Numbers relative to the epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b511a52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:35.370435Z",
     "iopub.status.busy": "2021-11-09T08:24:35.369774Z",
     "iopub.status.idle": "2021-11-09T08:24:45.892279Z",
     "shell.execute_reply": "2021-11-09T08:24:45.892858Z",
     "shell.execute_reply.started": "2021-11-09T07:54:22.907318Z"
    },
    "papermill": {
     "duration": 10.74732,
     "end_time": "2021-11-09T08:24:45.893042",
     "exception": false,
     "start_time": "2021-11-09T08:24:35.145722",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from  keras.models import load_model\n",
    "\n",
    "model_from_saved_checkpoint = load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef7aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:46.325426Z",
     "iopub.status.busy": "2021-11-09T08:24:46.324389Z",
     "iopub.status.idle": "2021-11-09T08:24:46.568908Z",
     "shell.execute_reply": "2021-11-09T08:24:46.569365Z",
     "shell.execute_reply.started": "2021-11-09T07:54:23.288972Z"
    },
    "papermill": {
     "duration": 0.46139,
     "end_time": "2021-11-09T08:24:46.569557",
     "exception": false,
     "start_time": "2021-11-09T08:24:46.108167",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59b2596",
   "metadata": {
    "papermill": {
     "duration": 0.217811,
     "end_time": "2021-11-09T08:24:47.005353",
     "exception": false,
     "start_time": "2021-11-09T08:24:46.787542",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# LSTM Predictions using testX and plotting line graph against Actual testY\n",
    "\n",
    "Due to scaling step done earlier with MinMaxScaler the predicted scale is between 0 and 1. \n",
    "Now, I need to transfer this scale to the original data scale (real value). for example:[0.58439621 0.58439621 0.58439621 ... 0.81262134 0.81262134 0.81262134], the pred answer transfer to :[250 100 50 60 .....]\n",
    "So here I am going to use `inverse_transform` to Scale back the data to the original representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57e509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:47.442254Z",
     "iopub.status.busy": "2021-11-09T08:24:47.441292Z",
     "iopub.status.idle": "2021-11-09T08:24:48.147090Z",
     "shell.execute_reply": "2021-11-09T08:24:48.148309Z",
     "shell.execute_reply.started": "2021-11-09T07:54:23.503949Z"
    },
    "papermill": {
     "duration": 0.924691,
     "end_time": "2021-11-09T08:24:48.148562",
     "exception": false,
     "start_time": "2021-11-09T08:24:47.223871",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transformation to original form and making the predictions\n",
    "\n",
    "# predicted_btc_price_test_data = regressor.predict(testX)\n",
    "predicted_btc_price_test_data = model_from_saved_checkpoint.predict(testX)\n",
    "\n",
    "predicted_btc_price_test_data = scaler_test.inverse_transform(predicted_btc_price_test_data.reshape(-1, 1))\n",
    "\n",
    "test_actual = scaler_test.inverse_transform(testY.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe4f8e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:48.631238Z",
     "iopub.status.busy": "2021-11-09T08:24:48.630519Z",
     "iopub.status.idle": "2021-11-09T08:24:48.869179Z",
     "shell.execute_reply": "2021-11-09T08:24:48.868519Z",
     "shell.execute_reply.started": "2021-11-09T07:54:24.206344Z"
    },
    "papermill": {
     "duration": 0.475269,
     "end_time": "2021-11-09T08:24:48.869315",
     "exception": false,
     "start_time": "2021-11-09T08:24:48.394046",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "\n",
    "plt.plot(predicted_btc_price_test_data, 'r', marker='.', label='Predicted Test')\n",
    "\n",
    "plt.plot(test_actual, marker='.', label='Actual Test')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e60010",
   "metadata": {
    "papermill": {
     "duration": 0.238642,
     "end_time": "2021-11-09T08:24:49.336671",
     "exception": false,
     "start_time": "2021-11-09T08:24:49.098029",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# LSTM Prediction using trainX and plotting line graph against Actual trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be035e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:49.804710Z",
     "iopub.status.busy": "2021-11-09T08:24:49.804055Z",
     "iopub.status.idle": "2021-11-09T08:24:50.080720Z",
     "shell.execute_reply": "2021-11-09T08:24:50.079836Z",
     "shell.execute_reply.started": "2021-11-09T07:54:24.406259Z"
    },
    "papermill": {
     "duration": 0.514588,
     "end_time": "2021-11-09T08:24:50.080872",
     "exception": false,
     "start_time": "2021-11-09T08:24:49.566284",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transformation to original form and making the predictions\n",
    "\n",
    "predicted_btc_price_train_data = model_from_saved_checkpoint.predict(trainX)\n",
    "\n",
    "predicted_btc_price_train_data = scaler_train.inverse_transform(predicted_btc_price_train_data.reshape(-1, 1))\n",
    "\n",
    "train_actual = scaler_train.inverse_transform(trainY.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe8243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:50.553036Z",
     "iopub.status.busy": "2021-11-09T08:24:50.548756Z",
     "iopub.status.idle": "2021-11-09T08:24:50.791501Z",
     "shell.execute_reply": "2021-11-09T08:24:50.791940Z",
     "shell.execute_reply.started": "2021-11-09T07:54:24.729679Z"
    },
    "papermill": {
     "duration": 0.481274,
     "end_time": "2021-11-09T08:24:50.792100",
     "exception": false,
     "start_time": "2021-11-09T08:24:50.310826",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "\n",
    "plt.plot(predicted_btc_price_train_data, 'r', marker='.', label='Predicted Train')\n",
    "\n",
    "plt.plot(train_actual, marker='.', label='Actual Train')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ddaef",
   "metadata": {
    "papermill": {
     "duration": 0.217656,
     "end_time": "2021-11-09T08:24:51.229330",
     "exception": false,
     "start_time": "2021-11-09T08:24:51.011674",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# RMSE - Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f528eac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T08:24:51.673734Z",
     "iopub.status.busy": "2021-11-09T08:24:51.672794Z",
     "iopub.status.idle": "2021-11-09T08:24:51.678780Z",
     "shell.execute_reply": "2021-11-09T08:24:51.679241Z",
     "shell.execute_reply.started": "2021-11-09T07:54:24.941735Z"
    },
    "papermill": {
     "duration": 0.229983,
     "end_time": "2021-11-09T08:24:51.679408",
     "exception": false,
     "start_time": "2021-11-09T08:24:51.449425",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmse_lstm_test = math.sqrt(mean_squared_error(test_actual, predicted_btc_price_test_data))\n",
    "\n",
    "print('Test RMSE: %.3f' % rmse_lstm_test)\n",
    "\n",
    "# With 2 Layers + Drop\n",
    "# out + lookback=5 => I got - Test RMSE: 1666.162  => This seems best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875de26",
   "metadata": {
    "papermill": {
     "duration": 0.219609,
     "end_time": "2021-11-09T08:24:52.119977",
     "exception": false,
     "start_time": "2021-11-09T08:24:51.900368",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# RMSE - Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65332faa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rmse_lstm_train = math.sqrt(mean_squared_error(train_actual, predicted_btc_price_train_data))\n",
    "print('Test RMSE: %.3f' % rmse_lstm_train)\n",
    "\n",
    "# With 2 Layers + Dropout + lookback=5 => I got - Test RMSE: 1047.916  => This seems best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46070fc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 155.774638,
   "end_time": "2021-11-09T08:24:56.343239",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-09T08:22:20.568601",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}